"""
ç¬¬18ç« ï¼šç¼–ç ä¸–ç•Œçš„æ¸©æŸ”ç§˜å¯† - å“ˆå¤«æ›¼æ ‘å®Œæ•´å®ç°
ä½œè€…ï¼šæ•°æ®ä¹‹å¿ƒå°è¯´ç»„
ä¸»é¢˜ï¼šå“ˆå¤«æ›¼ç¼–ç (Huffman Coding)ä¸å“ˆå¤«æ›¼æ ‘(Huffman Tree)

æœ¬æ–‡ä»¶åŒ…å«ï¼š
1. å“ˆå¤«æ›¼æ ‘èŠ‚ç‚¹ç±»çš„å®Œæ•´å®ç°
2. å­—ç¬¦é¢‘ç‡ç»Ÿè®¡åŠŸèƒ½
3. å“ˆå¤«æ›¼æ ‘æ„å»ºç®—æ³•
4. ç¼–ç è¡¨ç”Ÿæˆ
5. æ–‡æœ¬ç¼–ç ä¸è§£ç 
6. å‹ç¼©æ•ˆæœåˆ†æ
7. å®é™…åº”ç”¨ç¤ºä¾‹
"""

import heapq  # ä¼˜å…ˆé˜Ÿåˆ—ï¼Œç”¨äºæ„å»ºå“ˆå¤«æ›¼æ ‘
from collections import Counter, defaultdict  # è®¡æ•°å™¨å’Œé»˜è®¤å­—å…¸
import pickle  # ç”¨äºåºåˆ—åŒ–å“ˆå¤«æ›¼æ ‘
import os     # ç”¨äºæ–‡ä»¶æ“ä½œ


class HuffmanNode:
    """
    å“ˆå¤«æ›¼æ ‘èŠ‚ç‚¹ç±»
    
    å°±åƒä¼Šèè´å°”æ¸©æŸ”åœ°æ„å»ºå®¶æ—æ ‘ä¸€æ ·ï¼Œ
    å“ˆå¤«æ›¼æ ‘çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½æ‰¿è½½ç€é‡è¦çš„ä¿¡æ¯ï½
    """
    
    def __init__(self, char=None, freq=0, left=None, right=None):
        self.char = char    # å­—ç¬¦ï¼ˆå¶å­èŠ‚ç‚¹æ‰æœ‰å­—ç¬¦ï¼Œå†…éƒ¨èŠ‚ç‚¹ä¸ºNoneï¼‰
        self.freq = freq    # é¢‘ç‡ï¼ˆæƒé‡ï¼‰
        self.left = left    # å·¦å­æ ‘
        self.right = right  # å³å­æ ‘
    
    def __lt__(self, other):
        """
        å®šä¹‰èŠ‚ç‚¹æ¯”è¾ƒæ–¹æ³•ï¼Œè®©ä¼˜å…ˆé˜Ÿåˆ—èƒ½å¤Ÿæ­£ç¡®æ’åº
        é¢‘ç‡å°çš„èŠ‚ç‚¹ä¼˜å…ˆçº§æ›´é«˜ï¼ˆå°é¡¶å †ï¼‰
        """
        return self.freq < other.freq
    
    def __gt__(self, other):
        """å®šä¹‰å¤§äºæ¯”è¾ƒ"""
        return self.freq > other.freq
    
    def __eq__(self, other):
        """å®šä¹‰ç›¸ç­‰æ¯”è¾ƒ"""
        if other is None:
            return False
        if not isinstance(other, HuffmanNode):
            return False
        return self.freq == other.freq
    
    def is_leaf(self):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹"""
        return self.char is not None
    
    def __repr__(self):
        """èŠ‚ç‚¹çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ–¹ä¾¿è°ƒè¯•"""
        if self.is_leaf():
            return f"HuffmanNode('{self.char}', {self.freq})"
        else:
            return f"HuffmanNode(None, {self.freq})"


class HuffmanCoder:
    """
    å“ˆå¤«æ›¼ç¼–ç å™¨ç±»
    
    å°±åƒé»›èŠ™ä¼˜é›…åœ°å¤„ç†å¤æ‚ç®—æ³•ä¸€æ ·ï¼Œ
    è¿™ä¸ªç±»æ¸©æŸ”è€Œé«˜æ•ˆåœ°å¤„ç†æ–‡æœ¬å‹ç¼©ï½
    """
    
    def __init__(self):
        self.root = None           # å“ˆå¤«æ›¼æ ‘çš„æ ¹èŠ‚ç‚¹
        self.codes = {}           # å­—ç¬¦åˆ°ç¼–ç çš„æ˜ å°„è¡¨
        self.reverse_codes = {}   # ç¼–ç åˆ°å­—ç¬¦çš„æ˜ å°„è¡¨ï¼ˆç”¨äºè§£ç ï¼‰
    
    def _count_frequency(self, text):
        """
        ç»Ÿè®¡æ–‡æœ¬ä¸­æ¯ä¸ªå­—ç¬¦çš„å‡ºç°é¢‘ç‡
        
        å°±åƒå®‰å¦®ä»”ç»†æ•°ç€ä¹¦æ¶ä¸Šæ¯ç§ä¹¦çš„æ•°é‡ï¼Œ
        æˆ‘ä»¬éœ€è¦çŸ¥é“æ¯ä¸ªå­—ç¬¦å‡ºç°äº†å¤šå°‘æ¬¡ï½
        
        Args:
            text (str): è¾“å…¥æ–‡æœ¬
            
        Returns:
            dict: å­—ç¬¦é¢‘ç‡å­—å…¸ {å­—ç¬¦: é¢‘ç‡}
        """
        if not text:  # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œç›´æ¥è¿”å›ç©ºå­—å…¸
            return {}
        
        # ä½¿ç”¨Counteræ¥ç»Ÿè®¡é¢‘ç‡ï¼Œè¿™æ˜¯Pythonçš„è®¡æ•°å™¨ç±»
        # Counterä¼šè‡ªåŠ¨éå†æ–‡æœ¬ä¸­çš„æ¯ä¸ªå­—ç¬¦å¹¶ç»Ÿè®¡å‡ºç°æ¬¡æ•°
        frequency = Counter(text)
        
        print(f"ğŸ“Š å­—ç¬¦é¢‘ç‡ç»Ÿè®¡å®Œæˆï¼")
        print(f"   å‘ç° {len(frequency)} ç§ä¸åŒå­—ç¬¦")
        print(f"   æ–‡æœ¬æ€»é•¿åº¦ï¼š{len(text)} ä¸ªå­—ç¬¦")
        
        # æ˜¾ç¤ºé¢‘ç‡æœ€é«˜çš„å‡ ä¸ªå­—ç¬¦
        most_common = frequency.most_common(5)
        print(f"   å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—ç¬¦ï¼š")
        for char, freq in most_common:
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦çš„æ˜¾ç¤º
            display_char = repr(char) if char in [' ', '\n', '\t'] else char
            print(f"     {display_char}: {freq}æ¬¡ ({freq/len(text)*100:.1f}%)")
        
        return frequency
    
    def _build_huffman_tree(self, frequency):
        """
        æ„å»ºå“ˆå¤«æ›¼æ ‘
        
        å°±åƒå¸Œå¨…è€å¿ƒåœ°æ­å»ºç§¯æœ¨å¡”ä¸€æ ·ï¼Œ
        æˆ‘ä»¬ä»æœ€å°çš„é¢‘ç‡å¼€å§‹ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„å“ˆå¤«æ›¼æ ‘ï½
        
        Args:
            frequency (dict): å­—ç¬¦é¢‘ç‡å­—å…¸
            
        Returns:
            HuffmanNode: å“ˆå¤«æ›¼æ ‘çš„æ ¹èŠ‚ç‚¹
        """
        if not frequency:
            return None
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå­—ç¬¦ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ ‘
        if len(frequency) == 1:
            char, freq = list(frequency.items())[0]
            root = HuffmanNode(freq=freq)
            root.left = HuffmanNode(char=char, freq=freq)
            print(f"ğŸŒ± åªæœ‰ä¸€ä¸ªå­—ç¬¦ '{char}'ï¼Œåˆ›å»ºç®€å•æ ‘ç»“æ„")
            return root
        
        # åˆ›å»ºä¼˜å…ˆé˜Ÿåˆ—ï¼ˆå°é¡¶å †ï¼‰
        heap = []
        
        # ä¸ºæ¯ä¸ªå­—ç¬¦åˆ›å»ºå¶å­èŠ‚ç‚¹å¹¶æ”¾å…¥å †ä¸­
        for char, freq in frequency.items():  # éå†å­—ç¬¦é¢‘ç‡å­—å…¸
            node = HuffmanNode(char=char, freq=freq)  # åˆ›å»ºå¶å­èŠ‚ç‚¹
            heapq.heappush(heap, node)  # å°†èŠ‚ç‚¹æ”¾å…¥ä¼˜å…ˆé˜Ÿåˆ—ï¼ˆå°é¡¶å †ï¼‰
        
        print(f"ğŸŒ³ å¼€å§‹æ„å»ºå“ˆå¤«æ›¼æ ‘...")
        print(f"   åˆå§‹èŠ‚ç‚¹æ•°ï¼š{len(heap)}")
        
        step = 1
        # ä¸æ–­åˆå¹¶é¢‘ç‡æœ€å°çš„ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œç›´åˆ°åªå‰©ä¸€ä¸ªæ ¹èŠ‚ç‚¹
        while len(heap) > 1:  # å½“å †ä¸­è¿˜æœ‰å¤šä¸ªèŠ‚ç‚¹æ—¶ç»§ç»­åˆå¹¶
            # å–å‡ºé¢‘ç‡æœ€å°çš„ä¸¤ä¸ªèŠ‚ç‚¹
            left = heapq.heappop(heap)   # heappop()å–å‡ºå †é¡¶æœ€å°å…ƒç´ ï¼Œä½œä¸ºå·¦å­æ ‘
            right = heapq.heappop(heap)  # å†å–å‡ºä¸‹ä¸€ä¸ªæœ€å°å…ƒç´ ï¼Œä½œä¸ºå³å­æ ‘
            
            # åˆ›å»ºæ–°çš„å†…éƒ¨èŠ‚ç‚¹ï¼ˆä¸å¯¹åº”ä»»ä½•å­—ç¬¦ï¼Œåªæ˜¯ä¸­é—´èŠ‚ç‚¹ï¼‰
            merged_freq = left.freq + right.freq  # æ–°èŠ‚ç‚¹é¢‘ç‡=ä¸¤ä¸ªå­èŠ‚ç‚¹é¢‘ç‡ä¹‹å’Œ
            merged_node = HuffmanNode(char=None, freq=merged_freq, left=left, right=right)
            
            # å°†æ–°èŠ‚ç‚¹æ”¾å›å †ä¸­ï¼Œå®ƒä¼šæ ¹æ®é¢‘ç‡è‡ªåŠ¨æ’åº
            heapq.heappush(heap, merged_node)
            
            print(f"   æ­¥éª¤ {step}: åˆå¹¶é¢‘ç‡ {left.freq} + {right.freq} = {merged_freq}")
            step += 1
        
        root = heap[0]  # æœ€åå‰©ä¸‹çš„å°±æ˜¯æ ¹èŠ‚ç‚¹
        print(f"âœ¨ å“ˆå¤«æ›¼æ ‘æ„å»ºå®Œæˆï¼æ ¹èŠ‚ç‚¹é¢‘ç‡ï¼š{root.freq}")
        return root
    
    def _generate_codes(self, root):
        """
        ä»å“ˆå¤«æ›¼æ ‘ç”Ÿæˆç¼–ç è¡¨
        
        å°±åƒä¼Šèè´å°”æ¸©æŸ”åœ°ä¸ºæ¯ä¸ªå®¶æ—æˆå‘˜æ ‡è®°è·¯å¾„ï¼Œ
        æˆ‘ä»¬ä¸ºæ¯ä¸ªå­—ç¬¦åˆ†é…å”¯ä¸€çš„äºŒè¿›åˆ¶ç¼–ç ï½
        
        Args:
            root (HuffmanNode): å“ˆå¤«æ›¼æ ‘çš„æ ¹èŠ‚ç‚¹
        """
        if not root:
            return
        
        self.codes = {}
        self.reverse_codes = {}
        
        def dfs(node, code):
            """æ·±åº¦ä¼˜å…ˆæœç´¢ç”Ÿæˆç¼–ç """
            if node.is_leaf():  # åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹ï¼ˆæœ‰å­—ç¬¦çš„èŠ‚ç‚¹ï¼‰
                # å¶å­èŠ‚ç‚¹ï¼šä¿å­˜å­—ç¬¦çš„ç¼–ç 
                self.codes[node.char] = code if code else "0"  # å¦‚æœåªæœ‰ä¸€ä¸ªå­—ç¬¦ï¼Œç¼–ç ä¸º"0"
                self.reverse_codes[code if code else "0"] = node.char  # å»ºç«‹åå‘æ˜ å°„ç”¨äºè§£ç 
            else:
                # å†…éƒ¨èŠ‚ç‚¹ï¼šç»§ç»­å‘ä¸‹æœç´¢
                if node.left:  # å¦‚æœæœ‰å·¦å­æ ‘
                    dfs(node.left, code + "0")   # å‘å·¦èµ°ï¼Œç¼–ç æ·»åŠ "0"
                if node.right:  # å¦‚æœæœ‰å³å­æ ‘
                    dfs(node.right, code + "1")  # å‘å³èµ°ï¼Œç¼–ç æ·»åŠ "1"
        
        dfs(root, "")
        
        print(f"ğŸ“ ç¼–ç è¡¨ç”Ÿæˆå®Œæˆï¼")
        print(f"   å…±ç”Ÿæˆ {len(self.codes)} ä¸ªå­—ç¬¦çš„ç¼–ç ")
        
        # æ˜¾ç¤ºç¼–ç è¡¨ï¼ˆæŒ‰ç¼–ç é•¿åº¦æ’åºï¼‰
        sorted_codes = sorted(self.codes.items(), key=lambda x: len(x[1]))
        print(f"   ç¼–ç è¡¨ï¼ˆæŒ‰é•¿åº¦æ’åºï¼‰ï¼š")
        for char, code in sorted_codes[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            display_char = repr(char) if char in [' ', '\n', '\t'] else char
            print(f"     {display_char}: {code}")
        if len(sorted_codes) > 10:
            print(f"     ... è¿˜æœ‰ {len(sorted_codes) - 10} ä¸ªå­—ç¬¦")
    
    def fit(self, text):
        """
        è®­ç»ƒå“ˆå¤«æ›¼ç¼–ç å™¨
        
        å°±åƒå®‰å¦®è®¤çœŸå­¦ä¹ æ–°çŸ¥è¯†ä¸€æ ·ï¼Œ
        ç¼–ç å™¨éœ€è¦å…ˆå­¦ä¹ æ–‡æœ¬çš„ç‰¹å¾ï¼Œæ‰èƒ½é«˜æ•ˆå‹ç¼©ï½
        
        Args:
            text (str): è®­ç»ƒæ–‡æœ¬
        """
        print(f"ğŸ“ å¼€å§‹è®­ç»ƒå“ˆå¤«æ›¼ç¼–ç å™¨...")
        
        # ç¬¬ä¸€æ­¥ï¼šç»Ÿè®¡å­—ç¬¦é¢‘ç‡
        frequency = self._count_frequency(text)
        if not frequency:
            print("âš ï¸  è¾“å…¥æ–‡æœ¬ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒç¼–ç å™¨")
            return
        
        # ç¬¬äºŒæ­¥ï¼šæ„å»ºå“ˆå¤«æ›¼æ ‘
        self.root = self._build_huffman_tree(frequency)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç¼–ç è¡¨
        self._generate_codes(self.root)
        
        print(f"ğŸ‰ å“ˆå¤«æ›¼ç¼–ç å™¨è®­ç»ƒå®Œæˆï¼")
    
    def encode(self, text):
        """
        ç¼–ç æ–‡æœ¬
        
        å°±åƒé»›èŠ™å°†å¤æ‚çš„æƒ³æ³•è½¬åŒ–ä¸ºç®€æ´çš„ä»£ç ï¼Œ
        æˆ‘ä»¬å°†æ–‡æœ¬è½¬æ¢ä¸ºç´§å‡‘çš„äºŒè¿›åˆ¶ç¼–ç ï½
        
        Args:
            text (str): å¾…ç¼–ç çš„æ–‡æœ¬
            
        Returns:
            str: ç¼–ç åçš„äºŒè¿›åˆ¶å­—ç¬¦ä¸²
        """
        if not self.codes:
            raise ValueError("ç¼–ç å™¨å°šæœªè®­ç»ƒï¼è¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
        
        if not text:
            return ""
        
        # å°†æ¯ä¸ªå­—ç¬¦è½¬æ¢ä¸ºå¯¹åº”çš„ç¼–ç 
        encoded_bits = []  # å­˜å‚¨æ‰€æœ‰å­—ç¬¦çš„ç¼–ç 
        for char in text:  # éå†åŸæ–‡æœ¬çš„æ¯ä¸ªå­—ç¬¦
            if char in self.codes:  # å¦‚æœè¯¥å­—ç¬¦åœ¨ç¼–ç è¡¨ä¸­
                encoded_bits.append(self.codes[char])  # æ·»åŠ å¯¹åº”çš„äºŒè¿›åˆ¶ç¼–ç 
            else:
                # å¤„ç†è®­ç»ƒæ—¶æœªè§è¿‡çš„å­—ç¬¦ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¥½çš„å¤„ç†ï¼‰
                print(f"âš ï¸  è­¦å‘Šï¼šå­—ç¬¦ '{char}' ä¸åœ¨ç¼–ç è¡¨ä¸­ï¼Œè·³è¿‡")
        
        encoded_text = "".join(encoded_bits)  # å°†æ‰€æœ‰ç¼–ç è¿æ¥æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²
        
        # è®¡ç®—å‹ç¼©æ•ˆæœ
        original_bits = len(text) * 8  # å‡è®¾åŸæ–‡æ¯å­—ç¬¦8ä½ï¼ˆASCIIï¼‰
        compressed_bits = len(encoded_text)
        compression_ratio = (1 - compressed_bits / original_bits) * 100 if original_bits > 0 else 0
        
        print(f"ğŸ“¦ ç¼–ç å®Œæˆï¼")
        print(f"   åŸå§‹é•¿åº¦ï¼š{len(text)} å­—ç¬¦ ({original_bits} ä½)")
        print(f"   ç¼–ç é•¿åº¦ï¼š{compressed_bits} ä½")
        print(f"   å‹ç¼©ç‡ï¼š{compression_ratio:.1f}%")
        
        return encoded_text
    
    def decode(self, encoded_text):
        """
        è§£ç äºŒè¿›åˆ¶æ–‡æœ¬
        
        å°±åƒå¸Œå¨…è€å¿ƒåœ°è§£è¯»å¯†ç ä¸€æ ·ï¼Œ
        æˆ‘ä»¬å°†äºŒè¿›åˆ¶ç¼–ç è¿˜åŸä¸ºåŸå§‹æ–‡æœ¬ï½
        
        Args:
            encoded_text (str): ç¼–ç åçš„äºŒè¿›åˆ¶å­—ç¬¦ä¸²
            
        Returns:
            str: è§£ç åçš„åŸå§‹æ–‡æœ¬
        """
        if not self.root:
            raise ValueError("ç¼–ç å™¨å°šæœªè®­ç»ƒï¼è¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
        
        if not encoded_text:
            return ""
        
        decoded_chars = []  # å­˜å‚¨è§£ç åçš„å­—ç¬¦
        current_node = self.root  # ä»æ ¹èŠ‚ç‚¹å¼€å§‹
        
        # éå†æ¯ä¸ªäºŒè¿›åˆ¶ä½
        for bit in encoded_text:  # é€ä¸ªå¤„ç†ç¼–ç å­—ç¬¦ä¸²ä¸­çš„æ¯ä¸€ä½
            if bit == '0':  # å¦‚æœæ˜¯'0'ï¼Œå‘å·¦èµ°
                current_node = current_node.left
            elif bit == '1':  # å¦‚æœæ˜¯'1'ï¼Œå‘å³èµ°
                current_node = current_node.right
            else:
                raise ValueError(f"æ— æ•ˆçš„äºŒè¿›åˆ¶ä½ï¼š{bit}")  # é0é1çš„å­—ç¬¦æ˜¯é”™è¯¯çš„
            
            # åˆ°è¾¾å¶å­èŠ‚ç‚¹ï¼Œæ‰¾åˆ°ä¸€ä¸ªå­—ç¬¦
            if current_node.is_leaf():  # å¦‚æœåˆ°è¾¾å¶å­èŠ‚ç‚¹
                decoded_chars.append(current_node.char)  # è®°å½•æ‰¾åˆ°çš„å­—ç¬¦
                current_node = self.root  # é‡æ–°ä»æ ¹èŠ‚ç‚¹å¼€å§‹ä¸‹ä¸€ä¸ªå­—ç¬¦çš„è§£ç 
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ç»“æŸåœ¨æ ¹èŠ‚ç‚¹
        if current_node != self.root:
            print("âš ï¸  è­¦å‘Šï¼šç¼–ç ä¸å®Œæ•´ï¼Œå¯èƒ½å­˜åœ¨æˆªæ–­")
        
        decoded_text = "".join(decoded_chars)
        print(f"ğŸ“– è§£ç å®Œæˆï¼æ¢å¤äº† {len(decoded_text)} ä¸ªå­—ç¬¦")
        
        return decoded_text
    
    def get_code_table(self):
        """
        è·å–ç¼–ç è¡¨
        
        Returns:
            dict: å­—ç¬¦åˆ°ç¼–ç çš„æ˜ å°„è¡¨
        """
        return self.codes.copy()
    
    def save_model(self, filename):
        """
        ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        
        å°±åƒä¼Šèè´å°”ç»†å¿ƒåœ°ä¿å­˜ç ”ç©¶æˆæœï¼Œ
        æˆ‘ä»¬å°†ç¼–ç å™¨ä¿å­˜èµ·æ¥ä»¥ä¾¿é‡å¤ä½¿ç”¨ï½
        
        Args:
            filename (str): ä¿å­˜æ–‡ä»¶å
        """
        model_data = {
            'root': self.root,
            'codes': self.codes,
            'reverse_codes': self.reverse_codes
        }
        
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š{filename}")
    
    def load_model(self, filename):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            filename (str): æ¨¡å‹æ–‡ä»¶å
        """
        with open(filename, 'rb') as f:
            model_data = pickle.load(f)
        
        self.root = model_data['root']
        self.codes = model_data['codes']
        self.reverse_codes = model_data['reverse_codes']
        
        print(f"ğŸ“‚ æ¨¡å‹å·²ä» {filename} åŠ è½½å®Œæˆ")


class FileCompressor:
    """
    æ–‡ä»¶å‹ç¼©å™¨ç±»
    
    å°±åƒå¸Œå¨…ç”¨å·§å¦™çš„æ–¹æ³•è§£å†³å®é™…é—®é¢˜ï¼Œ
    è¿™ä¸ªç±»ä¸“é—¨å¤„ç†æ–‡ä»¶çš„å‹ç¼©å’Œè§£å‹ç¼©ï½
    """
    
    def __init__(self):
        self.coder = HuffmanCoder()
    
    def compress_file(self, input_file, output_file):
        """
        å‹ç¼©æ–‡ä»¶
        
        Args:
            input_file (str): è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ—œï¸  å¼€å§‹å‹ç¼©æ–‡ä»¶ï¼š{input_file}")
        
        # è¯»å–åŸå§‹æ–‡ä»¶
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                text = f.read()
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            with open(input_file, 'r', encoding='latin1') as f:
                text = f.read()
        
        if not text:
            print("âš ï¸  æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•å‹ç¼©")
            return
        
        # è®­ç»ƒç¼–ç å™¨å¹¶å‹ç¼©
        self.coder.fit(text)
        compressed_data = self.coder.encode(text)
        
        # ä¿å­˜å‹ç¼©æ–‡ä»¶ï¼ˆåŒ…å«å“ˆå¤«æ›¼æ ‘å’Œå‹ç¼©æ•°æ®ï¼‰
        with open(output_file, 'wb') as f:
            # ä¿å­˜å“ˆå¤«æ›¼æ ‘å’Œå‹ç¼©æ•°æ®
            compress_info = {
                'huffman_tree': self.coder.root,
                'compressed_data': compressed_data,
                'original_length': len(text)
            }
            pickle.dump(compress_info, f)
        
        # è®¡ç®—å‹ç¼©æ•ˆæœ
        original_size = os.path.getsize(input_file)
        compressed_size = os.path.getsize(output_file)
        compression_ratio = (1 - compressed_size / original_size) * 100
        
        print(f"âœ¨ æ–‡ä»¶å‹ç¼©å®Œæˆï¼")
        print(f"   åŸå§‹å¤§å°ï¼š{original_size:,} å­—èŠ‚")
        print(f"   å‹ç¼©å¤§å°ï¼š{compressed_size:,} å­—èŠ‚")
        print(f"   å‹ç¼©ç‡ï¼š{compression_ratio:.1f}%")
    
    def decompress_file(self, input_file, output_file):
        """
        è§£å‹ç¼©æ–‡ä»¶
        
        Args:
            input_file (str): å‹ç¼©æ–‡ä»¶è·¯å¾„
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“¦ å¼€å§‹è§£å‹ç¼©æ–‡ä»¶ï¼š{input_file}")
        
        # è¯»å–å‹ç¼©æ–‡ä»¶
        with open(input_file, 'rb') as f:
            compress_info = pickle.load(f)
        
        # æ¢å¤å“ˆå¤«æ›¼ç¼–ç å™¨
        self.coder.root = compress_info['huffman_tree']
        self.coder._generate_codes(self.coder.root)
        
        # è§£å‹ç¼©æ•°æ®
        decompressed_text = self.coder.decode(compress_info['compressed_data'])
        
        # ä¿å­˜è§£å‹ç¼©æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(decompressed_text)
        
        print(f"âœ¨ æ–‡ä»¶è§£å‹ç¼©å®Œæˆï¼")
        print(f"   æ¢å¤é•¿åº¦ï¼š{len(decompressed_text)} å­—ç¬¦")


def demonstrate_huffman_coding():
    """
    æ¼”ç¤ºå“ˆå¤«æ›¼ç¼–ç çš„å®Œæ•´è¿‡ç¨‹
    
    å°±åƒå®‰å¦®å…´å¥‹åœ°å±•ç¤ºæ–°å­¦åˆ°çš„çŸ¥è¯†ï¼Œ
    è®©æˆ‘ä»¬çœ‹çœ‹å“ˆå¤«æ›¼ç¼–ç æ˜¯å¦‚ä½•å·¥ä½œçš„ï½
    """
    print("ğŸ¯ å“ˆå¤«æ›¼ç¼–ç æ¼”ç¤ºå¼€å§‹ï¼")
    print("="*50)
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_texts = [
        "AAAAABBC",  # ç®€å•ç¤ºä¾‹
        "Hello, World! This is a test of Huffman coding.",  # è‹±æ–‡æ–‡æœ¬
        "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥æ¼”ç¤ºå“ˆå¤«æ›¼ç¼–ç çš„æ•ˆæœã€‚",  # ä¸­æ–‡æ–‡æœ¬
    ]
    
    for i, text in enumerate(sample_texts, 1):
        print(f"\nğŸ“ ç¤ºä¾‹ {i}ï¼š")
        print(f"åŸå§‹æ–‡æœ¬ï¼š{text}")
        
        # åˆ›å»ºç¼–ç å™¨
        coder = HuffmanCoder()
        
        # è®­ç»ƒå¹¶ç¼–ç 
        coder.fit(text)
        encoded = coder.encode(text)
        
        # è§£ç éªŒè¯
        decoded = coder.decode(encoded)
        
        # éªŒè¯æ­£ç¡®æ€§
        is_correct = text == decoded
        print(f"âœ… è§£ç éªŒè¯ï¼š{'é€šè¿‡' if is_correct else 'å¤±è´¥'}")
        
        if not is_correct:
            print(f"   åŸæ–‡ï¼š{text}")
            print(f"   è§£ç ï¼š{decoded}")
        
        print("-" * 30)


def analyze_compression_efficiency():
    """
    åˆ†æä¸åŒç±»å‹æ–‡æœ¬çš„å‹ç¼©æ•ˆç‡
    
    å°±åƒé»›èŠ™æ·±å…¥åˆ†æç®—æ³•æ€§èƒ½ï¼Œ
    è®©æˆ‘ä»¬çœ‹çœ‹å“ˆå¤«æ›¼ç¼–ç åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ï½
    """
    print("\nğŸ” å‹ç¼©æ•ˆç‡åˆ†æ")
    print("="*50)
    
    test_cases = [
        ("å‡åŒ€åˆ†å¸ƒ", "ABCDEFGHIJKLMNOPQRSTUVWXYZ" * 10),
        ("é«˜åº¦é‡å¤", "AAAAAAAAAA" + "B" * 2 + "C"),
        ("è‡ªç„¶è¯­è¨€", "The quick brown fox jumps over the lazy dog. " * 5),
        ("ç¨‹åºä»£ç ", "for i in range(10):\n    print(f'Hello {i}')\n" * 3),
    ]
    
    for name, text in test_cases:
        print(f"\nğŸ“Š æµ‹è¯•æ¡ˆä¾‹ï¼š{name}")
        print(f"æ–‡æœ¬é•¿åº¦ï¼š{len(text)} å­—ç¬¦")
        
        coder = HuffmanCoder()
        coder.fit(text)
        encoded = coder.encode(text)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        original_bits = len(text) * 8
        compressed_bits = len(encoded)
        compression_ratio = (1 - compressed_bits / original_bits) * 100
        
        print(f"å‹ç¼©å‰ï¼š{original_bits} ä½")
        print(f"å‹ç¼©åï¼š{compressed_bits} ä½")
        print(f"å‹ç¼©ç‡ï¼š{compression_ratio:.1f}%")
        
        # åˆ†æç¼–ç é•¿åº¦åˆ†å¸ƒ
        code_lengths = [len(code) for code in coder.codes.values()]
        avg_length = sum(code_lengths) / len(code_lengths)
        print(f"å¹³å‡ç¼–ç é•¿åº¦ï¼š{avg_length:.2f} ä½")
        print(f"ç¼–ç é•¿åº¦èŒƒå›´ï¼š{min(code_lengths)} - {max(code_lengths)} ä½")


if __name__ == "__main__":
    print("ğŸŒŸ æ¬¢è¿æ¥åˆ°ç¼–ç ä¸–ç•Œçš„æ¸©æŸ”ç§˜å¯†ï¼")
    print("è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢å“ˆå¤«æ›¼ç¼–ç çš„ç¥å¥‡é­…åŠ›ï½")
    print()
    
    # è¿è¡Œæ¼”ç¤º
    demonstrate_huffman_coding()
    
    # åˆ†æå‹ç¼©æ•ˆç‡
    analyze_compression_efficiency()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("æ„Ÿè°¢ä½“éªŒå“ˆå¤«æ›¼ç¼–ç çš„ä¼˜é›…ä¸–ç•Œï½")
    print("å°±åƒä¼Šèè´å°”è¯´çš„ï¼šæœ€æ¸©æŸ”çš„å…³æ€€ï¼Œå°±æ˜¯ç»™æœ€éœ€è¦çš„äººæœ€å¤šçš„çˆ± ğŸ’•") 